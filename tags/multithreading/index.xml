<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Multithreading on 7sharp9</title>
    <link>http://7sharpnine.com/tags/multithreading/</link>
    <description>Recent content in Multithreading on 7sharp9</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Dave Thomas</copyright>
    <lastBuildDate>Fri, 28 Jan 2011 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://7sharpnine.com/tags/multithreading/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Sockets and Bockets 4</title>
      <link>http://7sharpnine.com/2011/01/28/2011-01-28-sockets-and-bockets-part-4/</link>
      <pubDate>Fri, 28 Jan 2011 00:00:00 +0000</pubDate>
      
      <guid>http://7sharpnine.com/2011/01/28/2011-01-28-sockets-and-bockets-part-4/</guid>
      <description>

&lt;h2 id=&#34;welcome-to-part-4&#34;&gt;Welcome to part 4&lt;/h2&gt;

&lt;p&gt;If you were looking forward to some exciting new F# code this time your going
to be disappointed, however if you are like me and like looking at graphs and
stats and digging in deeper into the code then your going to enjoy this, lets
get started&amp;hellip;&lt;!-- more --&gt;&lt;/p&gt;

&lt;p&gt;I set up a 5 minute test with 50 clients connecting to the server with a 15ms
interval between each one.  Once connected each client receives a 128 byte
message from the server every 100ms so this will be a 500 messages per second
test.  I am going to be using an excellent product called &lt;a href=&#34;http://bit.ly/e4ToaO&#34;&gt;YourKit Profilerfor .NET&lt;/a&gt; it can do both memory and CPU profiling as
well as displaying telemetry for things like thread count, stack contents,
memory allocations etc.  It can be configured to be a lot less intrusive than
a lot of other profilers and I have had a lot of success using it.  You can
download a demo from their site using the link above.  I will be doing some
other articles on using profiling and analysis tools later on so stay tuned
for those too.  All of the graphs and information gathered in this post come
from YourKits output during CPU and memory profiling.&lt;/p&gt;

&lt;p&gt;Before we start here&amp;rsquo;s a reminder of what the client code looks like, this is
a simple test client using Brian&amp;rsquo;s code as mentioned in
&lt;a href=&#34;http://7sharpnine.com/posts/sockets-and-bockets-1/&#34;&gt;Part1&lt;/a&gt; I have highlighted the lines that
have changed below.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-fsharp&#34;&gt;    open System.Net
    open System.Net.Sockets  
    let quoteSize = 128  
    type System.Net.Sockets.TcpClient with
      member client.AsyncConnect(server, port, clientIndex) =
        Async.FromBeginEnd(server, port,(client.BeginConnect : IPAddress * int * _ * _ -&amp;gt; _), client.EndConnect)  
    let clientRequestQuoteStream (clientIndex, server, port:int) =
      async {
        let client = new System.Net.Sockets.TcpClient()
        do!  client.AsyncConnect(server,port, clientIndex)
        let stream = client.GetStream()
        let! header = stream.AsyncRead 1 // read header
        while true do
          let! bytes = stream.AsyncRead quoteSize
          if Array.length bytes &amp;lt;&amp;gt; quoteSize then
            printfn &amp;quot;client incorrect checksum&amp;quot;
      }  
    let myLock = new obj()  
    let clientAsync clientIndex =
      async {
        do! Async.Sleep(clientIndex*15)
        if clientIndex % 10 = 0 then
          lock myLock (fun() -&amp;gt; printfn &amp;quot;%d clients...&amp;quot; clientIndex)
        try
          do! clientRequestQuoteStream (clientIndex, IPAddress.Loopback, 10003)
        with e -&amp;gt;
          printfn &amp;quot;CLIENT %d ERROR: %A&amp;quot; clientIndex e
          //raise e
      }  
    Async.Parallel [ for i in 1 .. 50 -&amp;gt; clientAsync i ]
      |&amp;gt; Async.Ignore
      |&amp;gt; Async.Start
    System.Console.ReadKey() |&amp;gt; ignore
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;cpu-and-threading-performance&#34;&gt;CPU and threading performance&lt;/h2&gt;

&lt;p&gt;First of all lets look at the CPU results from the &lt;em&gt;IAsync&lt;/em&gt; pattern:&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://lh5.googleusercontent.com/-3H8-TiiB-VI/TwYhL2mvYsI/AAAAAAAABQI/z8dmiHBvTJE/mcnamara-cpu1.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;Heres the same run from the SAEA pattern:&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://lh3.googleusercontent.com/-yGB2zdE3kGM/TwYhLPrUmLI/AAAAAAAABP8/Y6CIMWOi4Gk/Bocket-cpu2.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;You can see that both the number of threads and the amount of CPU is a quite a
lot less in the SAEA pattern.  The spike at the beginning is the allocation of
buffers for the BocketPool.&lt;/p&gt;

&lt;p&gt;Now lets move on to memory and garbage collection.&lt;/p&gt;

&lt;h2 id=&#34;memory-allocation&#34;&gt;Memory Allocation&lt;/h2&gt;

&lt;p&gt;Here&amp;rsquo;s a graph of the heap and process memory allocation in the &lt;strong&gt;IAsync&lt;/strong&gt;
pattern, green is generation 0, blue is generation 1 and orange is the large
object heap.  There&amp;rsquo;s also red for generation 2 but the results are behind the
others and they are only small 0,2 MB peaks at 5 to 15 second intervals.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://lh3.googleusercontent.com/-PalohQxAkOg/TwYhL6hR5JI/AAAAAAAABQQ/NtCLYc43OZc/mcnamara-mem1.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;Heres the same but for the SAEA pattern, there are red peaks every 10- 20
second intervals of 0.2MB hidden under the others.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://lh3.googleusercontent.com/-Nadz1nXQ7lg/TwYhLBXMvcI/AAAAAAAABQM/xCfuXkzkekM/Bocket-mem1.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;As you can see the heap memory is around half the size and the process memory is 15MB less.&lt;/p&gt;

&lt;h2 id=&#34;memory-hotspots&#34;&gt;Memory Hotspots&lt;/h2&gt;

&lt;p&gt;Finally here&amp;rsquo;s a couple of screen shot of the hot spots for memory allocations
in both implementations&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://lh4.googleusercontent.com/-n3QWLgvNjq8/TwYhLX8cIZI/AAAAAAAABQA/LkeRno775Ew/s800/IAsync-hot.png&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;IAsync&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;



&lt;figure &gt;
    
        &lt;img src=&#34;https://lh5.googleusercontent.com/-PSX_YUfxkgU/TwYhMr40DTI/AAAAAAAABQY/D8bgLS6kNwc/s800/SAEA-hot.png&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;SAEA&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;You can clearly the &lt;strong&gt;IAsync&lt;/strong&gt; allocations are not present in the SAEA
implementation and there are 310,188 of them, that&amp;rsquo;s 27% of the total garbage!&lt;/p&gt;

&lt;h2 id=&#34;final-thoughts&#34;&gt;Final thoughts&lt;/h2&gt;

&lt;p&gt;The SAEA pattern definitely cuts down on memory and CPU usage, yes it adds a
lot of complexity but if your application is dealing with a very high volume
of traffic or clients and you need optimal performance then I think its the
way to go.&lt;/p&gt;

&lt;p&gt;The optimisations don&amp;rsquo;t stop there either, if you think about it the receive
Bocketpool is not even used here, if we collapsed all of the BocketPools into
a single contiguous store then we would use even less resources, this means we
could support even more clients or throughput.  In a typical high volume
scenario you are looking at doubling your throughput or number of client
connections.&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s definitely a lot more or interesting things to explore in this area.&lt;/p&gt;

&lt;p&gt;As usual any comments are welcome.&lt;/p&gt;

&lt;p&gt;See you next time&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>